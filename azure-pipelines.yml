# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
  batch: true
  branches:
    include:
    - master

pool: MyPool

# Install Python. The version must match the version on the Databricks cluster.
steps:
- task: UsePythonVersion@0
  displayName: 'Use Python 3.7'
  inputs:
    versionSpec: '3.x' 
    addToPath: true 
    architecture: 'x64'

# Install required Python modules, including databricks-connect, required to execute a unit test
# on a cluster.
- script: |
    pip install pytest requests setuptools wheel
    pip install -U databricks-connect==6.4.*
    pip install pyspark==3.2.1
  displayName: 'Load Python Dependencies'

- checkout: self
  persistCredentials: true
  clean: true

- script: git checkout master
  displayName: 'Get Latest Branch'
  
- script: |
    python -m unittest tests/test_*.py --junit-xml=$(Build.Repository.LocalPath)/logs/TEST-LOCAL.xml $(Build.Repository.LocalPath)/libraries/python/dbxdemo/test*.py || true
    ls logs
  displayName: 'Run Python Unit Tests for library code'
